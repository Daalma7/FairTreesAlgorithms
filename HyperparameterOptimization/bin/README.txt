This is the tutorial for the complete execution and all functionalities of the multiobjective optimisation algorithm made for getting  good binary classifiers in terms of some criteria, including fairness ones, which you can specify.

There are several executable files in this folder, including exescript.sh, fairness.py, totalpo-py, calculatemeasures.py and plots_2.py we will what do they do next, what kind of parameters and syntax do the accept, and an example of which is the intended order of execution.


************************
***   exescript.sh   ***
************************

This file contains sentences for executing the rest of the files, written in bash. It is created as a script that would allow us to program what do we want to execute, and ease the task of writing correct code. Its content is thought to be changed following the user needs.


***********************
***   fairness.py   ***
***********************

This file contains the code for executing a multiobjective evolutionary optimisation algorithm, to a binary classification problem. Parameters accepted are:

	- alg=(algorithm): Algorithm to be executed. Possible algorithms are nsga2, smsemoa and grea. The default is nsga2

	- nidn=(integer): Number of individuals to have each population during algorithm execution. The default is 50.

	- ngen=(integer): Number of generations for the algorithm to be executed (stopping criteria). The default is 300

	- dat=(dataset): Name of the dataset in csv format. The file should be placed at the folder named data. Initial dataset are adult, german, propublica_recidivism, propublica_violent_recidivism and ricci. The default is german.

	- var=(variable): Name of the sensitive variable for the dataset variable. Sensitive considered variables for each of the previous datasets are: adult-race, german-age, propublica_recidivism-race, propublica_violent_recidivism-race, ricci-Race. The default is the first variable of a the dataset (It is absolutely recommendable to change)

	- bseed=(integer): Base seed which will be used in the first run of the algorithm. It's used for train-validation-test split for the data, and other possible needs which require randomness. The default is 100.

	- nruns=(integer): Number of runs for the algorithm to be executed with different seeds. Each run takes consecutive seeds with respect to the previous one, starting from the base seed. The default is 10.

	- model=(model abbreviation): Model to use. Possible models are Decision Tree (DT) and Logistic Regression (LR). The default is DT.

	- obj=(comm separated list of objectives): List of objectives to be used. Possible objectives are: gmean_inv, dem_fpr, dem_ppv, dem_pnr, num_leaves, data_weight_avg_depth. You can add and combine them as you please. The default is gmean_inv,dem_fpr.

	- extra=(comm separated list of objectives): List of objectives to not be used in optimization, but to be calculated in individuals generated. Possible values are the same as in obj. The default is None.

	- help: Shows this help and ends.

An example sentence for execute this file could be:

	python fairness.py nind=60 ngen=300 alg=nsga2 dat=propublica_recidivism var=race bseed=100 nruns=10 model=DT obj=gmean_inv,dem_fpr,dem_ppv,num_leaves

Results are saved into the corresponding results/(algorithm)/individuals folder. There are 3 kind of result files:

	- individuals_... files: contain all individuals generated by the algorithm for a specific run.
	- individuals_pareto_... files: contain all Pareto optimal individuals generated by the algorithm for a specific run.
	- general_individuals_pareto_... files: contain all Pareto optimal individuals generated by the algorithm considering all runs.


**********************
***   totalpo.py   ***
**********************

This file contains the code to get all previous results from the executions of fairness.py with specific parameters and calculate the general pareto front for that problem and objectives. Parameters accepted are:

	- alg=(comm separated list of algorithms): Algorithms from which to take results. Possible algorithms are nsga2, smsemoa and grea. The default is nsga2,smsemoa,grea

	- dat=(dataset): Name of the dataset in csv format. The file should be placed at the folder named data. Initial dataset are adult, german, propublica_recidivism, propublica_violent_recidivism and ricci. The default is german.

	- var=(variable): Name of the sensitive variable for the dataset variable. Sensitive considered variables for each of the previous datasets are: adult-race, german-age, propublica_recidivism-race, propublica_violent_recidivism-race, ricci-Race. The default is the first variable of a the dataset (It is absolutely recommendable to change)
	
	- model=(model abbreviation): Model to use. Possible models are Decision Tree (DT) and Logistic Regression (LR). The default is DT.
	
	- obj=(comm separated list of objectives): List of objectives to be used. Possible objectives are: gmean_inv, dem_fpr, dem_ppv, dem_pnr, num_leaves, data_weight_avg_depth. You can add and combine them as you please. The default is gmean_inv,dem_fpr. IMPORTANT: Objectives should be written in the same order as they were written at the fairness.py execution sentence.

	- extra=(comm separated list of objectives): List of objectives to not be used in optimization, but to be calculated in individuals generated. Possible values are the same as in obj. The default is None. IMPORTANT: Objectives should be written in the same order as they were written at the fairness.py execution sentence.

	- help: Shows this help and ends.

An example sentence for execute this file could be:

	python totalpo.py alg=nsga2,smsemoa,grea dat=propublica_recidivism var=race model=DT obj=gmean_inv,dem_fpr,dem_ppv,num_leaves

Results are saved into results/general_pareto_fronts folder.


********************************
***   calculatemeasures.py   ***
********************************

This file contains the code to calculate relevant quality measures for the pareto optimal files corresponding to the parameters given. Possible parameters are:

	- alg=(comm separated list of algorithms): Algorithms from which to take results. Possible algorithms are nsga2, smsemoa and grea. The default is nsga2,smsemoa,grea

	- dat=(dataset): Name of the dataset in csv format. The file should be placed at the folder named data. Initial dataset are adult, german, propublica_recidivism, propublica_violent_recidivism and ricci. The default is german.

	- var=(variable): Name of the sensitive variable for the dataset variable. Sensitive considered variables for each of the previous datasets are: adult-race, german-age, propublica_recidivism-race, propublica_violent_recidivism-race, ricci-Race. The default is the first variable of a the dataset (It is absolutely recommendable to change)
	
	- obj=(comm separated list of objectives): List of objectives to be used. Possible objectives are: gmean_inv, dem_fpr, dem_ppv, dem_pnr, num_leaves, data_weight_avg_depth. You can add and combine them as you please. The default is gmean_inv,dem_fpr. IMPORTANT: Objectives should be written in the same order as they were written at the fairness.py execution sentence.

	-- extra=(comm separated list of objectives): List of objectives to not be used in optimization, but to be calculated in individuals generated. Possible values are the same as in obj. The default is None. IMPORTANT: Objectives should be written in the same order as they were written at the fairness.py execution sentence.

	- model=(model abbreviation): Model to use. Possible models are Decision Tree (DT) and Logistic Regression (LR). The default is DT.

	- help: Shows this help and ends.

An example sentence for execute this file could be:

	python calculatemeasures.py alg=nsga2,smsemoa,grea dat=propublica_recidivism var=race model=DT obj=gmean_inv,dem_fpr,dem_ppv,num_leaves

Results are saved into the corresponding results/measures folder.

**********************
***   plots_2.py   ***
**********************

Plots different data. This file is highly tied to executions made, so it is adviceable to modify it depending on which executions and parameters will you use




